import os
import json
import openai
import soundfile
import numpy as np
import file_dbaccess
from pathlib import Path
from loguru import logger
from base64 import b64decode
from datetime import datetime
from pydub import AudioSegment
from wavinfo import WavInfoReader
from openai.embeddings_utils import get_embedding, cosine_similarity


EMBEDDING_MODEL = 'text-embedding-ada-002'
COMPLETIONS_MODEL = "text-davinci-003"
QUESTION_COMPLETIONS_API_PARAMS = {
    # We use temperature of 0.0 because it gives the most predictable, factual answer.
    "temperature": 0.0,
    "max_tokens": 200,
    "model": COMPLETIONS_MODEL,
}

REGULAR_COMPLETIONS_API_PARAMS = {
    "temperature": 0.5,
    "max_tokens": 500,
    "model": COMPLETIONS_MODEL,
}

class CommandHandler:
    def __init__(self):
        self.openai = openai
        self.openai.api_key = os.getenv("OPENAI_KEY")
        self.db = file_dbaccess.LocalFileDbAccess("database.csv")
        self.db.ensureExists()
        # self.data_dir = Path.cwd() / "responses"
        self.image_dir = Path.cwd() / "images"
        self.audio_dir = Path.cwd() / "audio"
        self.image_dir.mkdir(parents=True, exist_ok=True)
        
        # self.data_dir.mkdir(parents=True, exist_ok=True)


    
    def execute_command(self, msg:str):
        now = datetime.now()
        dt_string = now.strftime("%d/%m/%Y %H:%M:%S")
        self.df = self.db.get()
        """
        Check the message and exexute relevant command
        """
        if msg.startswith("/h"):
            return("Commands:\n\n/q [question] - Ask a question\n/s [message] - Save a message\n/f [message] - Find related messages\n/d [message] - Generate Image\n/h - Show this help menu")

        # Question answering
        elif msg.startswith("/q "):
            # Get the question
            question = str(msg.split("/q ")[1])
            # Construct the prompt
            prompt = self.construct_prompt(question, self.df, top_n=3)
            # Get the answer
            response = openai.Completion.create(prompt=prompt, **QUESTION_COMPLETIONS_API_PARAMS)
            return response["choices"][0]["text"]

        elif msg.startswith("/s "):
            data_to_save = msg.split("/s ")[1]
            # Save the massage to the database
            text_embedding = get_embedding(data_to_save, engine='text-embedding-ada-002')
            self.df = self.df.append({"time":dt_string,"message":data_to_save, "ada_search": text_embedding},ignore_index=True)
            self.db.save(self.df)
            return "Message saved successfully!"

        # Find related messages
        elif msg.startswith("/f "):
            query = str(msg.split("/f ")[1])
            most_similar = self.return_most_similiar(query, self.df, top_n=3)
            msg_reply = ''
            for i in range(len(most_similar)):
                msg_reply += most_similar.iloc[i]['time'] + ': ' + most_similar.iloc[i]['message'] + '\n'
            return msg_reply

        elif msg.startswith("/d"):
            return self.generate_image(msg)
            


        # Placeholder for other commands
        elif msg.startswith("/"):
            return("Sorry, I don't understand the command")


        # Get a regular completion
        else:
            # Just get a regular completion from the model
            COMPLETIONS_API_PARAMS = {
                # We use temperature of 0.0 because it gives the most predictable, factual answer.
                "temperature": 0.0,
                "max_tokens": 200,
                "model": COMPLETIONS_MODEL,
            }
            response = openai.Completion.create(prompt=msg, **REGULAR_COMPLETIONS_API_PARAMS)
            print (response)
            return response["choices"][0]["text"]
            


    def construct_prompt(self,question, df, top_n=3):
        try:
            # Get the context
            context = self.generate_context(question, df, top_n)
            header =  header = """Answer the question in details, based only on the provided context and nothing else, and if the answer is not contained within the text below, say "w.", do not invent or deduce!\n\nContext:\n"""
            return header + "".join(context) + "Q: " + question + "\n A:"
        except Exception as e:
            logger.error(str(e))
            return("aw snap something went wrong")

    def generate_context(self,question, df, top_n=3):
        try:
            most_similiar = self.return_most_similiar(question, df, top_n)
            # Get the top 3 most similar messages
            top_messages = most_similiar["message"].values
            # Concatenate the top 3 messages into a single string
            context = '\n '.join(top_messages)
            return context
        except Exception as e:
            logger.error(str(e))

    def return_most_similiar(self,question, df, top_n=3):
        try:
            # Get the embedding for the question
            
            question_embedding = get_embedding(question, engine='text-embedding-ada-002')
            # Get the embedding for the messages in the database
            df["ada_search"] = df["ada_search"].apply(eval).apply(np.array)
            # Get the similarity between the question and the messages in the database
            df['similarity'] = df.ada_search.apply(lambda x: cosine_similarity(x, question_embedding))
            # Get the index of the top 3 most similar message
            most_similiar = df.sort_values('similarity', ascending=False).head(top_n)
            return most_similiar
        except Exception as e:
            logger.error(str(e))

    def generate_image(self, prompt):
        try:
            response = self.openai.Image.create(
            prompt=prompt,
            n=1,
            size="1024x1024",
            response_format="b64_json",
            )


            for index, image_dict in enumerate(response["data"]):
                image_data = b64decode(image_dict["b64_json"])
                image_file = self.image_dir / f"{response['created']}.png"
                with open(image_file, mode="wb") as png:
                    png.write(image_data)
                return str(image_file)
        except Exception as e:
            logger.error(str(e))
            return str(e)
    
    def transcript(self, audio_file):
        try:
            audio_file = self.convertToWav(audio_file)
            data= open(audio_file, "rb")
            transcript = openai.Audio.transcribe("whisper-1", data)
            
            return transcript["text"]
        

        except Exception as e:
            logger.error(str(e))
            return("aw snap something went wrong")
        


    #Get audio file extention
    def getExtention(self, audio_file):
        logger.info("Getting audio file extention")
        filename, file_extension = os.path.splitext(audio_file)
        return filename, file_extension

    # Convert to wav if needed
    def convertToWav(self, audio_file):
        logger.info("Input File:" +  audio_file)
        filename, file_extension = self.getExtention(audio_file)
        output_file = filename + ".wav"
        logger.info("Output File:" +  output_file)
        if file_extension == ".mp3":
            logger.info("Converting from mp3 to WAV")
            sound = AudioSegment.from_mp3(audio_file)
            sound.export(output_file, format="wav")
        if file_extension == ".ogg":
            logger.info("Converting from ogg to WAV")
            sound = AudioSegment.from_ogg(audio_file)
            sound.export(output_file, format="wav")
        if file_extension == ".mp4":
            logger.info("Converting from mp4 to WAV")
            sound = AudioSegment.from_file(audio_file, "mp4")
            sound.export(output_file, format="wav")
        if file_extension == ".wma":
            logger.info("Converting from wma to WAV")
            sound = AudioSegment.from_file(audio_file, "wma")
            sound.export(output_file, format="wav")
        if file_extension == ".aac":
            logger.info("Converting from aac to WAV")
            sound = AudioSegment.from_file(audio_file, "aac")
            sound.export(output_file, format="wav")
            logger.debug(str(data))

        logger.info("Chaniging sample rate to PCM_16")
        data, samplerate = soundfile.read(output_file)
        soundfile.write(output_file, data, samplerate, subtype='PCM_16')
        logger.info("Removing original audio file")
        os.remove(audio_file)
        return output_file



